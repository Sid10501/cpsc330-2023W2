{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# CPSC 330 - Applied Machine Learning \n",
    "\n",
    "## Homework 3: Preprocessing \n",
    "### Associated lectures: [Lectures 4, 5, 6](https://github.com/UBC-CS/cpsc330-2023s/tree/main/lectures) \n",
    "\n",
    "**Due date: Monday, Feb 5, 11:59pm. See the [HW schedule](https://github.com/UBC-CS/cpsc330-2023W2#deliverable-due-dates-tentative)**. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hashlib import sha1\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "<hr>\n",
    "\n",
    "_Points: 6_\n",
    "\n",
    "Follow the [homework submission instructions](https://github.com/UBC-CS/cpsc330-2023W2/blob/master/docs/homework_instructions.md), and the summary at the end of this HW.\n",
    "\n",
    "**You <u>may</u> work with a partner on this homework and submit your assignment as a group.** Below are some instructions on working as a group.  \n",
    "- You can also work on your own if you prefer.\n",
    "- The maximum group size is 2.\n",
    "- Use group work as an opportunity to collaborate and learn new things from each other. \n",
    "- Be respectful to each other and make sure you understand all the concepts in the assignment well. \n",
    "- It's your responsibility to make sure that the assignment is submitted by one of the group members before the deadline. \n",
    "\n",
    "_Note: The assignments will get gradually more open-ended as we progress through the course. In many cases, there won't be a single correct solution. Sometimes you will have to make your own choices and your own decisions (for example, on what parameter values to use when they are not explicitly provided in the instructions). Use your own judgment in such cases and justify your choices, if necessary._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3247a4b883a670c7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Introduction <a name=\"in\"></a>\n",
    "<hr>\n",
    "\n",
    "A crucial step when using machine learning algorithms on real-world datasets is preprocessing. This homework will give you some practice of data preprocessing and building a supervised machine learning pipeline on a real-world dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Introducing the dataset\n",
    "<hr>\n",
    "\n",
    "In this lab, you will be working on [the adult census dataset](https://www.kaggle.com/uciml/adult-census-income#). Download the CSV and save it as `adult.csv` under the data folder in this homework folder. \n",
    "\n",
    "This is a classification dataset and the classification task is to predict whether income exceeds 50K per year or not based on the census data. You can find more information on the dataset and features [here](http://archive.ics.uci.edu/ml/datasets/Adult).\n",
    "\n",
    "The starter code below loads the data CSV (assuming that it is saved as `adult.csv` under the data folder). \n",
    "\n",
    "_Note that many popular datasets have sex as a feature where the possible values are male and female. This representation reflects how the data were collected and is not meant to imply that, for example, gender is binary._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 15)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census_df = pd.read_csv(\"data/adult.csv\")\n",
    "census_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Data splitting \n",
    "\n",
    "_Points: 2_\n",
    "\n",
    "In order to avoid violation of the golden rule, the first step before we do anything is splitting the data. \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Split the data into `train_df` (40%) and `test_df` (60%) with `random_state = 123`. Keep the target column (`income`) in the splits so that we can use it in the exploratory data analysis.  \n",
    "\n",
    "_Usually having more data for training is a good idea. But here I'm using 40%/60% split because running cross-validation with this dataset can take a while on a modest laptop. A smaller training data means it won't take too long to train the model on your laptop. A side advantage of this would be that with a bigger test split, we'll have a more reliable estimate of the model performance!_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_1.1\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "otter_assign_solution_cell"
    ]
   },
   "outputs": [],
   "source": [
    "train_df = None\n",
    "test_df = None\n",
    "\n",
    "train_df, test_df = train_test_split(census_df, test_size=0.60, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise 2: Exploratory data analysis (EDA) <a name=\"2\"></a> \n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine our `train_df`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>?</td>\n",
       "      <td>77053</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82</td>\n",
       "      <td>Private</td>\n",
       "      <td>132870</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>18</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>Private</td>\n",
       "      <td>264663</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>34</td>\n",
       "      <td>Private</td>\n",
       "      <td>216864</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3770</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>150601</td>\n",
       "      <td>10th</td>\n",
       "      <td>6</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>3770</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32554</th>\n",
       "      <td>32</td>\n",
       "      <td>Private</td>\n",
       "      <td>116138</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>310152</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13024 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age workclass  fnlwgt     education  education.num      marital.status  \\\n",
       "0       90         ?   77053       HS-grad              9             Widowed   \n",
       "1       82   Private  132870       HS-grad              9             Widowed   \n",
       "4       41   Private  264663  Some-college             10           Separated   \n",
       "5       34   Private  216864       HS-grad              9            Divorced   \n",
       "6       38   Private  150601          10th              6           Separated   \n",
       "...    ...       ...     ...           ...            ...                 ...   \n",
       "32554   32   Private  116138       Masters             14       Never-married   \n",
       "32556   22   Private  310152  Some-college             10       Never-married   \n",
       "32557   27   Private  257302    Assoc-acdm             12  Married-civ-spouse   \n",
       "32559   58   Private  151910       HS-grad              9             Widowed   \n",
       "32560   22   Private  201490       HS-grad              9       Never-married   \n",
       "\n",
       "            occupation   relationship                race     sex  \\\n",
       "0                    ?  Not-in-family               White  Female   \n",
       "1      Exec-managerial  Not-in-family               White  Female   \n",
       "4       Prof-specialty      Own-child               White  Female   \n",
       "5        Other-service      Unmarried               White  Female   \n",
       "6         Adm-clerical      Unmarried               White    Male   \n",
       "...                ...            ...                 ...     ...   \n",
       "32554     Tech-support  Not-in-family  Asian-Pac-Islander    Male   \n",
       "32556  Protective-serv  Not-in-family               White    Male   \n",
       "32557     Tech-support           Wife               White  Female   \n",
       "32559     Adm-clerical      Unmarried               White  Female   \n",
       "32560     Adm-clerical      Own-child               White    Male   \n",
       "\n",
       "       capital.gain  capital.loss  hours.per.week native.country income  \n",
       "0                 0          4356              40  United-States  <=50K  \n",
       "1                 0          4356              18  United-States  <=50K  \n",
       "4                 0          3900              40  United-States  <=50K  \n",
       "5                 0          3770              45  United-States  <=50K  \n",
       "6                 0          3770              40  United-States  <=50K  \n",
       "...             ...           ...             ...            ...    ...  \n",
       "32554             0             0              11         Taiwan  <=50K  \n",
       "32556             0             0              40  United-States  <=50K  \n",
       "32557             0             0              38  United-States  <=50K  \n",
       "32559             0             0              40  United-States  <=50K  \n",
       "32560             0             0              20  United-States  <=50K  \n",
       "\n",
       "[13024 rows x 15 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see some missing values represented with a \"?\". Probably these were the questions not answered by some people during the census.  Usually `.describe()` or `.info()` methods would give you information on missing values. But here, they won't pick \"?\" as missing values because they are encoded as strings instead of an actual NaN in Python. So let's replace them with `np.nan` before we carry out EDA. If you do not do it, you'll encounter an error later on when you try to pass this data to a classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13024, 15)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df.replace(\"?\", np.nan)\n",
    "test_df = test_df.replace(\"?\", np.nan)\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77053</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82</td>\n",
       "      <td>Private</td>\n",
       "      <td>132870</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>18</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>Private</td>\n",
       "      <td>264663</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>34</td>\n",
       "      <td>Private</td>\n",
       "      <td>216864</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3770</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>150601</td>\n",
       "      <td>10th</td>\n",
       "      <td>6</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>3770</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32554</th>\n",
       "      <td>32</td>\n",
       "      <td>Private</td>\n",
       "      <td>116138</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>310152</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13024 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age workclass  fnlwgt     education  education.num      marital.status  \\\n",
       "0       90       NaN   77053       HS-grad              9             Widowed   \n",
       "1       82   Private  132870       HS-grad              9             Widowed   \n",
       "4       41   Private  264663  Some-college             10           Separated   \n",
       "5       34   Private  216864       HS-grad              9            Divorced   \n",
       "6       38   Private  150601          10th              6           Separated   \n",
       "...    ...       ...     ...           ...            ...                 ...   \n",
       "32554   32   Private  116138       Masters             14       Never-married   \n",
       "32556   22   Private  310152  Some-college             10       Never-married   \n",
       "32557   27   Private  257302    Assoc-acdm             12  Married-civ-spouse   \n",
       "32559   58   Private  151910       HS-grad              9             Widowed   \n",
       "32560   22   Private  201490       HS-grad              9       Never-married   \n",
       "\n",
       "            occupation   relationship                race     sex  \\\n",
       "0                  NaN  Not-in-family               White  Female   \n",
       "1      Exec-managerial  Not-in-family               White  Female   \n",
       "4       Prof-specialty      Own-child               White  Female   \n",
       "5        Other-service      Unmarried               White  Female   \n",
       "6         Adm-clerical      Unmarried               White    Male   \n",
       "...                ...            ...                 ...     ...   \n",
       "32554     Tech-support  Not-in-family  Asian-Pac-Islander    Male   \n",
       "32556  Protective-serv  Not-in-family               White    Male   \n",
       "32557     Tech-support           Wife               White  Female   \n",
       "32559     Adm-clerical      Unmarried               White  Female   \n",
       "32560     Adm-clerical      Own-child               White    Male   \n",
       "\n",
       "       capital.gain  capital.loss  hours.per.week native.country income  \n",
       "0                 0          4356              40  United-States  <=50K  \n",
       "1                 0          4356              18  United-States  <=50K  \n",
       "4                 0          3900              40  United-States  <=50K  \n",
       "5                 0          3770              45  United-States  <=50K  \n",
       "6                 0          3770              40  United-States  <=50K  \n",
       "...             ...           ...             ...            ...    ...  \n",
       "32554             0             0              11         Taiwan  <=50K  \n",
       "32556             0             0              40  United-States  <=50K  \n",
       "32557             0             0              38  United-States  <=50K  \n",
       "32559             0             0              40  United-States  <=50K  \n",
       "32560             0             0              20  United-States  <=50K  \n",
       "\n",
       "[13024 rows x 15 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"?\" symbols are now replaced with NaN values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 `describe()` method\n",
    "\n",
    "_Points: 5_\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Examine the output of `train_df.describe()` with `include='all'` argument and store it in a variable called `census_summary`.\n",
    "2. What is the highest hours per week someone reported? Store it in a variable called `max_hours_per_week`.\n",
    "3. What is the most frequently occurring occupation in this dataset? Store it in a variable called `most_freq_occupation`.\n",
    "4. Store the column names of the columns with missing values as a list in a variable called `missing_vals_cols`. \n",
    "5. Store the column names of all numeric-looking columns as a list in a variable called `numeric_cols`.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_2.1\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": [
     "otter_assign_solution_cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13024.000000</td>\n",
       "      <td>12284</td>\n",
       "      <td>1.302400e+04</td>\n",
       "      <td>13024</td>\n",
       "      <td>13024.000000</td>\n",
       "      <td>13024</td>\n",
       "      <td>12281</td>\n",
       "      <td>13024</td>\n",
       "      <td>13024</td>\n",
       "      <td>13024</td>\n",
       "      <td>13024.000000</td>\n",
       "      <td>13024.000000</td>\n",
       "      <td>13024.000000</td>\n",
       "      <td>12783</td>\n",
       "      <td>13024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Private</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4153</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5936</td>\n",
       "      <td>1649</td>\n",
       "      <td>5195</td>\n",
       "      <td>11158</td>\n",
       "      <td>8700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11717</td>\n",
       "      <td>9875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.546913</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.884759e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.057432</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1079.831695</td>\n",
       "      <td>86.543074</td>\n",
       "      <td>40.395654</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.610225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.040895e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.553084</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7322.034546</td>\n",
       "      <td>403.025863</td>\n",
       "      <td>12.285347</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.376900e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.170962e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.778990e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.365655e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.184622e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>4356.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 age workclass        fnlwgt education  education.num  \\\n",
       "count   13024.000000     12284  1.302400e+04     13024   13024.000000   \n",
       "unique           NaN         8           NaN        16            NaN   \n",
       "top              NaN   Private           NaN   HS-grad            NaN   \n",
       "freq             NaN      9123           NaN      4153            NaN   \n",
       "mean       38.546913       NaN  1.884759e+05       NaN      10.057432   \n",
       "std        13.610225       NaN  1.040895e+05       NaN       2.553084   \n",
       "min        17.000000       NaN  1.376900e+04       NaN       1.000000   \n",
       "25%        28.000000       NaN  1.170962e+05       NaN       9.000000   \n",
       "50%        37.000000       NaN  1.778990e+05       NaN      10.000000   \n",
       "75%        48.000000       NaN  2.365655e+05       NaN      12.000000   \n",
       "max        90.000000       NaN  1.184622e+06       NaN      16.000000   \n",
       "\n",
       "            marital.status      occupation relationship   race    sex  \\\n",
       "count                13024           12281        13024  13024  13024   \n",
       "unique                   7              14            6      5      2   \n",
       "top     Married-civ-spouse  Prof-specialty      Husband  White   Male   \n",
       "freq                  5936            1649         5195  11158   8700   \n",
       "mean                   NaN             NaN          NaN    NaN    NaN   \n",
       "std                    NaN             NaN          NaN    NaN    NaN   \n",
       "min                    NaN             NaN          NaN    NaN    NaN   \n",
       "25%                    NaN             NaN          NaN    NaN    NaN   \n",
       "50%                    NaN             NaN          NaN    NaN    NaN   \n",
       "75%                    NaN             NaN          NaN    NaN    NaN   \n",
       "max                    NaN             NaN          NaN    NaN    NaN   \n",
       "\n",
       "        capital.gain  capital.loss  hours.per.week native.country income  \n",
       "count   13024.000000  13024.000000    13024.000000          12783  13024  \n",
       "unique           NaN           NaN             NaN             40      2  \n",
       "top              NaN           NaN             NaN  United-States  <=50K  \n",
       "freq             NaN           NaN             NaN          11717   9875  \n",
       "mean     1079.831695     86.543074       40.395654            NaN    NaN  \n",
       "std      7322.034546    403.025863       12.285347            NaN    NaN  \n",
       "min         0.000000      0.000000        1.000000            NaN    NaN  \n",
       "25%         0.000000      0.000000       40.000000            NaN    NaN  \n",
       "50%         0.000000      0.000000       40.000000            NaN    NaN  \n",
       "75%         0.000000      0.000000       45.000000            NaN    NaN  \n",
       "max     99999.000000   4356.000000       99.000000            NaN    NaN  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census_summary = train_df.describe(include = 'all')\n",
    "census_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": [
     "otter_assign_solution_cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_hours_per_week = train_df['hours.per.week'].max()\n",
    "\n",
    "max_hours_per_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": [
     "otter_assign_solution_cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Prof-specialty'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_freq_occupation = train_df['occupation'].value_counts().idxmax()\n",
    "\n",
    "most_freq_occupation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "otter_assign_solution_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['workclass', 'occupation', 'native.country']\n",
      "['age', 'fnlwgt', 'education.num', 'capital.gain', 'capital.loss', 'hours.per.week']\n"
     ]
    }
   ],
   "source": [
    "missing_vals_cols = train_df.columns[train_df.isnull().any()].tolist()\n",
    "\n",
    "numeric_cols = train_df.select_dtypes(include = 'number').columns.tolist()\n",
    "\n",
    "print(missing_vals_cols)\n",
    "print(numeric_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 2.2 Visualizing features\n",
    "\n",
    "_Points: 5_\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Visualize the histograms of numeric features.  \n",
    "2. From the visualizations, which features seem relevant for the given prediction task?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_2.2\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "otter_assign_solution_cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 3000x2000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(30, 20))\n",
    "train_df[numeric_cols].hist(bins = 30, edgecolor = 'black', grid = False, linewidth = 1.2)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br>Based on the visualization, age, education.num, and hours.per.week seem the most relevant for the prediction task. The task is to predict whether the income exceeds 50K per year or not based on the census data. \n",
    "\n",
    "- Age can be a major factor in predicting this since a higher age may represent more experience in an industry, suggesting higher salaries. \n",
    "\n",
    "- Another important variable can be education.num. A person who has a master's or PhD degree would have more knowledge and experience than a less educated individual, which can suggest higher income while working in some industry. \n",
    "\n",
    "- While hours.per.week might seem like another relevant feature in the sense that working a higher number of hours can lead to higher pay due to overtime, however upon looking at the histogram, the majority of the count lies in the 30 to 40-hour range, suggesting that most of the population in the data work the usual hours and working overtime may not lead to higher pay.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 2.3 Identify transformations to apply\n",
    "\n",
    "_Points: 13_\n",
    "\n",
    "Before passing this data to a machine learning model, we need to apply some transformations on different features. Below we are providing possible transformations which can be applied on each column in `census_df`.  \n",
    "\n",
    "**Your tasks:**\n",
    "1. Write your justification or explanation for each row in the explanation column. An example explanation is given for the age column. \n",
    "\n",
    "> Note: This question is a bit open-ended. If you do not agree with the provided transformation, feel free to argue your case in the explanation. That said, in this assignment, go with the transformations provided below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_2.3\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Feature | Transformation | Explanation\n",
    "| --- | ----------- | ----- |\n",
    "| age | scaling |  A numeric feature with no missing values. Good idea to apply scaling, as the range of values (17 to 90) is quite different compared to other numeric features.|\n",
    "| workclass | imputation, one-hot encoding | To tackle categorical variables, we use one-hot encoding as a transformation technique. Since workclass is a categorical variable, we can convert it to binary values making it suitable for models that require numerical inputs. Furthermore, workclass also has missing values(NaN), so to handle those cases, imputation seems like an ideal technique to transform the data. |\n",
    "| fnlwgt | drop | fnlwgt column does not seem relevant for prediction in this case. Hence it is better to drop the column since it does not provide us with a meaningful data. |\n",
    "| education | ordinal encoding | Education variable may have an inherent order. For instance, HS-grad, bachelors, pHD, etc. These degrees are ranked based on these education levels suggesting an ordinal relationship. This transformation would also help preserve the ordinal relationship between different education categories while converting them into numeric values. |\n",
    "| education.num | drop | Since we have already encoded education as ordinal, education.num becomes redundant. We can drop this column to avoid multicollinearity and simplify the dimensionality of the dataset. |\n",
    "| marital.status | one-hot encoding  | Similar to workclass, marital.status is a categorical variable. To handle this, we would apply one-hot encoding and convert it to binary values making it suitable for models that require numerical inputs. |\n",
    "| occupation | imputation, one-hot encoding  | occupation is also a categorical variable, hence one-hot encoding would be an ideal technique. Imputation also is a relevant transformation since there are NaN values in the dataset. |\n",
    "| relationship | one-hot encoding  | relationship is again a categorical variable, we can convert it to binary values making it suitable for models that require numerical inputs. Hence one-hot encoding would be an ideal transformation technique. |\n",
    "| race | drop  | race does not seem to be an appropriate predictor to predict the target variable. Hence to reduce the dimensionality and complexity of the dataset, we can drop the race column. |\n",
    "| sex | one-hot encoding with \"binary=True\" | For this dataset, attribute sex is a categorical variable with a value of either Male or Female. Hence one-hot encoding is the ideal transformation. Moreover, the additonal argument \"binary = True\" specifies that only one column should be created representing the binary nature of the sex feature |\n",
    "| capital.gain | scaling | From the summary of the numeric variables, we can see that capital.gain is a numeric column and has a range from 0.00 to 99999.00. The range of the values is quite different compared to other numeric features, hence it would be a good idea to apply scaling as a transformation technique.  | \n",
    "| capital.loss | scaling | capital.loss is again a numeric column and has a range from 0.00 to 4356.00. The range of the values is quite different compared to other numeric features, hence it would be good idea to apply scaling as a transformation technique. |\n",
    "| hours.per.week | scaling | hours.per.week is again a numeric column and has a range from 1.00 to 99.00. The range of the values is quite different compared to other numeric features, hence it would be good idea to apply scaling as a transformation technique. |\n",
    "| native.country | imputation, one-hot encoding | native.country is a categorical variable, we can convert it to binary values making it suitable for models that require numerical inputs. Furthermore, native.country has missing values(NaN), so to handle those cases, imputation seems like an ideal technique to transform the data.  | \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Identify feature types \n",
    "\n",
    "_Points: 5_\n",
    "\n",
    "**Your tasks:**\n",
    "1. Based on the types of transformations you want to apply on the features, identify different feature types and store them in the variables below as lists.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_2.4\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": [
     "otter_assign_solution_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Fill in the lists below.\n",
    "numeric_features = ['age', 'capital.gain', 'capital.loss', 'hours.per.week']\n",
    "categorical_features = ['workclass', 'marital.status', 'occupation', 'relationship', 'native.country']\n",
    "ordinal_features = ['education']\n",
    "binary_features = ['sex']\n",
    "drop_features = ['fnlwgt', 'education.num', 'race']\n",
    "target = \"income\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Baseline models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Separating feature vectors and targets  \n",
    "\n",
    "_Points: 2_\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Create `X_train`, `y_train`, `X_test`, `y_test` from `train_df` and `test_df`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_3.1\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": [
     "otter_assign_solution_cell"
    ]
   },
   "outputs": [],
   "source": [
    "X_train = None\n",
    "y_train = None\n",
    "X_test = None\n",
    "y_test = None\n",
    "\n",
    "X_train = train_df.drop(columns=[target])\n",
    "y_train = train_df[target]\n",
    "X_test = test_df.drop(columns=[target])\n",
    "y_test = test_df[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Dummy classifier\n",
    "\n",
    "_Points: 2_\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Carry out 5-fold cross-validation using `scikit-learn`'s `cross_validate` function with `return_train_scores=True` and store the results as a dataframe named `dummy_df` where each row corresponds to the results from a cross-validation fold. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_3.2\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": [
     "otter_assign_solution_cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.008013</td>\n",
       "      <td>0.005494</td>\n",
       "      <td>0.758157</td>\n",
       "      <td>0.758230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.007055</td>\n",
       "      <td>0.006951</td>\n",
       "      <td>0.758157</td>\n",
       "      <td>0.758230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007210</td>\n",
       "      <td>0.005011</td>\n",
       "      <td>0.758157</td>\n",
       "      <td>0.758230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.006113</td>\n",
       "      <td>0.006018</td>\n",
       "      <td>0.758157</td>\n",
       "      <td>0.758230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005865</td>\n",
       "      <td>0.005126</td>\n",
       "      <td>0.758449</td>\n",
       "      <td>0.758157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score  train_score\n",
       "0  0.008013    0.005494    0.758157     0.758230\n",
       "1  0.007055    0.006951    0.758157     0.758230\n",
       "2  0.007210    0.005011    0.758157     0.758230\n",
       "3  0.006113    0.006018    0.758157     0.758230\n",
       "4  0.005865    0.005126    0.758449     0.758157"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_df = None \n",
    "\n",
    "dummy_model = DummyClassifier(strategy=\"most_frequent\")\n",
    "cv_results = cross_validate(dummy_model, X_train, y_train, cv=5, return_train_score=True)\n",
    "\n",
    "dummy_df = pd.DataFrame(cv_results)\n",
    "dummy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 3.3 Discussion\n",
    "\n",
    "_Points: 2_\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Hopefully, you were able to run cross-validation with dummy classifier successfully in the question above. At this point, if you train [`sklearn`'s `SVC`](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) model on `X_train` and `y_train` would it work? Why or why not? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_3.3\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we train sklearn's SVC model on X_train and y_train, it will not work because SVC requires numeric values as input, and variables like workclass, relationship, etc, are categorical values. Furthermore, SVC would be unable to handle missing or null values that we have in workclass, occupation, etc. Finally, SVC would not give us accurate results without us scaling the data first, and a few variables with large range values would bias it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Preprocessing\n",
    "<hr>\n",
    "\n",
    "In this dataset, we have different types of features: numeric features, an ordinal feature, categorical features, and a binary feature. We want to apply different transformations on different columns and therefore we need a column transformer. In this exercise, first, we'll define different transformations on different types of features and then will create a `scikit-learn`'s `ColumnTransformer`. For example, the code below creates a `numeric_transformer` for numeric features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the exercises below, you'll create transformers for other types of features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Preprocessing ordinal features\n",
    "\n",
    "_Points: 5_\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Create a transformer called `ordinal_transformer` for our ordinal features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_4.1\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": [
     "otter_assign_solution_cell"
    ]
   },
   "outputs": [],
   "source": [
    "ordinal_transformer = None\n",
    "\n",
    "ordinal_transformer = OrdinalEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Preprocessing binary features\n",
    "\n",
    "_Points: 2_\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Create a transformer called `binary_transformer` for our binary features.\n",
    "\n",
    "> _Note that many popular datasets have sex as a feature where the possible values are male and female. This representation reflects how the data were collected and is not meant to imply that, for example, gender is binary._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_4.2\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "tags": [
     "otter_assign_solution_cell"
    ]
   },
   "outputs": [],
   "source": [
    "binary_transformer = None\n",
    "binary_transformer = OneHotEncoder(drop='if_binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Preprocessing categorical features\n",
    "\n",
    "_Points: 4_\n",
    "\n",
    "In Exercise 2.3, we saw that there are 3 categorical features with missing values. So first we need to impute the missing values and then encode these features with one-hot encoding. For the purpose of this assignment, let's just have imputation as the first step for all categorical features even when they do not have missing values. This should be OK because if a feature doesn't have any missing value,  imputation won't be applied. \n",
    "\n",
    "If we want to apply more than one transformation on a set of features, we need to create a [`scikit-learn` `Pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html). For example, for categorical features we can create a `scikit-learn` `Pipeline` with first step as imputation and the second step as one-hot encoding. \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Create a `sklearn` `Pipeline` using [`make_pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html) called `categorical_transformer` for our categorical features with two steps: `SimpleImputer` for imputation with `strategy=\"constant\"` and `fill_value=\"missing\"` and `OneHotEncoder` with `handle_unknown=\"ignore\"` and `sparse=False` for one-hot encoding. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_4.3\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": [
     "otter_assign_solution_cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                 SimpleImputer(fill_value=&#x27;missing&#x27;, strategy=&#x27;constant&#x27;)),\n",
       "                (&#x27;onehotencoder&#x27;,\n",
       "                 OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse_output=False))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                 SimpleImputer(fill_value=&#x27;missing&#x27;, strategy=&#x27;constant&#x27;)),\n",
       "                (&#x27;onehotencoder&#x27;,\n",
       "                 OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse_output=False))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(fill_value=&#x27;missing&#x27;, strategy=&#x27;constant&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('simpleimputer',\n",
       "                 SimpleImputer(fill_value='missing', strategy='constant')),\n",
       "                ('onehotencoder',\n",
       "                 OneHotEncoder(handle_unknown='ignore', sparse_output=False))])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_transformer = None\n",
    "\n",
    "categorical_transformer = make_pipeline(SimpleImputer(strategy=\"constant\", fill_value=\"missing\"), OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "\n",
    "categorical_transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Creating a column transformer. \n",
    "\n",
    "_Points: 7_\n",
    "\n",
    "**Your tasks:**\n",
    "1. Create a `sklearn` `ColumnTransformer` named `preprocessor` using [`make_column_transformer`](https://scikit-learn.org/stable/modules/generated/sklearn.compose.make_column_transformer.html) with the transformers defined in the previous exercises. Use the sequence below in the column transformer and add a \"drop\" step for the `drop_features` in the end.  \n",
    "    - `numeric_transformer`\n",
    "    - `ordinal_transformer`\n",
    "    - `binary_transformer`\n",
    "    - `categorical_transformer`\n",
    "2. Transform the data by calling `fit_transform` on the training set and save it as a dataframe in a variable called `transformed_df`. How many new columns have been created in the preprocessed data in comparison to the original `X_train`? Store the difference between the number of columns in `transformed_df` and `X_train` in a variable called `n_new_cols`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_4.4\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "tags": [
     "otter_assign_solution_cell"
    ]
   },
   "outputs": [],
   "source": [
    "preprocessor = None\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (numeric_transformer, numeric_features),\n",
    "    (ordinal_transformer, ordinal_features),\n",
    "    (binary_transformer, binary_features),\n",
    "    (categorical_transformer, categorical_features),\n",
    "    ('drop', drop_features)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "tags": [
     "otter_assign_solution_cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_df = None\n",
    "n_new_cols = None\n",
    "\n",
    "transformed_data = preprocessor.fit_transform(X_train)\n",
    "\n",
    "transformed_df = pd.DataFrame(transformed_data)\n",
    "\n",
    "n_new_cols = transformed_df.shape[1] - X_train.shape[1]\n",
    "\n",
    "n_new_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: Building models \n",
    "\n",
    "Now that we have preprocessed features, we are ready to build models. Below, I'm providing the function we used in class which returns mean cross-validation score along with standard deviation for a given model. Use it to keep track of your results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "results_dict = {}  # dictionary to store all the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_std_cross_val_scores(model, X_train, y_train, **kwargs):\n",
    "    \"\"\"\n",
    "    Returns mean and std of cross validation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model :\n",
    "        scikit-learn model\n",
    "    X_train : numpy array or pandas DataFrame\n",
    "        X in the training data\n",
    "    y_train :\n",
    "        y in the training data\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "        pandas Series with mean scores from cross_validation\n",
    "    \"\"\"\n",
    "\n",
    "    scores = cross_validate(model, X_train, y_train, **kwargs)\n",
    "\n",
    "    mean_scores = pd.DataFrame(scores).mean()\n",
    "    std_scores = pd.DataFrame(scores).std()\n",
    "    out_col = []\n",
    "\n",
    "    for i in range(len(mean_scores)):\n",
    "        out_col.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores[i], std_scores[i])))\n",
    "\n",
    "    return pd.Series(data=out_col, index=mean_scores.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I'm showing an example where I call `mean_std_cross_val_scores` with `DummyClassifier`. The function calls `cross_validate` with the passed arguments and returns a series with mean cross-validation results and std of cross-validation. When you train new models, you can just add the results of these models in `results_dict`, which can be easily converted to a dataframe so that you can have a table with all your results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ws/_grt5pdj4j385s9jf9wg606h0000gn/T/ipykernel_56363/4158382658.py:26: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  out_col.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores[i], std_scores[i])))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dummy</th>\n",
       "      <td>0.045 (+/- 0.008)</td>\n",
       "      <td>0.019 (+/- 0.002)</td>\n",
       "      <td>0.758 (+/- 0.000)</td>\n",
       "      <td>0.758 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                fit_time         score_time         test_score  \\\n",
       "dummy  0.045 (+/- 0.008)  0.019 (+/- 0.002)  0.758 (+/- 0.000)   \n",
       "\n",
       "             train_score  \n",
       "dummy  0.758 (+/- 0.000)  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline model\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy = DummyClassifier(random_state = 42)\n",
    "pipe = make_pipeline(preprocessor, dummy)\n",
    "results_dict[\"dummy\"] = mean_std_cross_val_scores(\n",
    "    pipe, X_train, y_train, cv=5, return_train_score=True\n",
    ")\n",
    "results_df = pd.DataFrame(results_dict).T\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 5.1 Trying different classifiers\n",
    "\n",
    "_Points: 10_\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. For each of the models in the starter code below: \n",
    "    - Define a pipeline with two steps: `preprocessor` from 4.4 and the model as your classifier. \n",
    "    - Carry out 5-fold cross-validation with the pipeline and get the mean cross-validation scores with std by calling the `mean_std_cross_val_scores` function above. \n",
    "    - Store the results in a dataframe called `income_pred_results_df` with the model names in the `models` dictionary below as the index and each row representing results returned by `mean_std_cross_val_scores` function above. In other words, `income_pred_results_df` should look similar to the `results_df` dataframe above with more rows for the models below. \n",
    "    \n",
    "> This might take a while to run. Be patient! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"decision tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"kNN\": KNeighborsClassifier(),\n",
    "    \"RBF SVM\": SVC(random_state=42),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_5.1\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "tags": [
     "otter_assign_solution_cell"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ws/_grt5pdj4j385s9jf9wg606h0000gn/T/ipykernel_56363/4158382658.py:26: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  out_col.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores[i], std_scores[i])))\n",
      "/var/folders/ws/_grt5pdj4j385s9jf9wg606h0000gn/T/ipykernel_56363/4158382658.py:26: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  out_col.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores[i], std_scores[i])))\n",
      "/var/folders/ws/_grt5pdj4j385s9jf9wg606h0000gn/T/ipykernel_56363/4158382658.py:26: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  out_col.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores[i], std_scores[i])))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>decision tree</th>\n",
       "      <th>kNN</th>\n",
       "      <th>RBF SVM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.127 (+/- 0.012)</td>\n",
       "      <td>0.043 (+/- 0.006)</td>\n",
       "      <td>5.213 (+/- 0.310)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.019 (+/- 0.001)</td>\n",
       "      <td>0.079 (+/- 0.018)</td>\n",
       "      <td>2.517 (+/- 0.324)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_score</th>\n",
       "      <td>0.819 (+/- 0.004)</td>\n",
       "      <td>0.834 (+/- 0.006)</td>\n",
       "      <td>0.847 (+/- 0.006)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_score</th>\n",
       "      <td>0.987 (+/- 0.001)</td>\n",
       "      <td>0.883 (+/- 0.002)</td>\n",
       "      <td>0.849 (+/- 0.002)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 decision tree                kNN            RBF SVM\n",
       "fit_time     0.127 (+/- 0.012)  0.043 (+/- 0.006)  5.213 (+/- 0.310)\n",
       "score_time   0.019 (+/- 0.001)  0.079 (+/- 0.018)  2.517 (+/- 0.324)\n",
       "test_score   0.819 (+/- 0.004)  0.834 (+/- 0.006)  0.847 (+/- 0.006)\n",
       "train_score  0.987 (+/- 0.001)  0.883 (+/- 0.002)  0.849 (+/- 0.002)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "income_pred_results_df = None \n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    \n",
    "    pipeline = make_pipeline(preprocessor, model)\n",
    "    results[name] = mean_std_cross_val_scores(\n",
    "        pipeline, X_train, y_train, cv = 5, return_train_score = True\n",
    "    )\n",
    "\n",
    "\n",
    "income_pred_results_df = pd.DataFrame(results)\n",
    "\n",
    "income_pred_results_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": [
     "otter_assign_solution_cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 5.2 Discussion \n",
    "\n",
    "_Points: 5_\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Examine the train and validation accuracies and `fit` and `score` times for all the models in the results above. How do the validation accuracies compare to the `DummyClassifier` model? Which model has the best validation accuracy? Which model is the fastest one? Which model is overfitting the most and the least?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_5.2\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- On comparing the validation accuracies with the DummyClassifier, all the other models perform better than the DummyClassifier, indicating that the other models provide better predictions.\n",
    "\n",
    "- Based on the above output, the RBF SVM model gives us the best validation accuracy, with the train_score being 0.849 and the test_score being 0.847, suggesting consistency in predicting the target. The fastest model is the kNN model with a fit_time of 0.043, however, the score time for the decision_tree model is the fastest at 0.019.\n",
    "\n",
    "- The decision tree model is overfitting the most. The reason is that the train_score for the decision_tree model is 0.987, suggesting extremely high accuracy on the training data. But, when we look at the test_score, it is 0.819, which is significantly less than the train_score, suggesting that the model is not working as well on unseen data.\n",
    "\n",
    "- RBF SVM has the least overfitting since the train and test scores (0.849 and 0.847, respectively) are almost identical. The kNN model has a moderate level of overfitting based on the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 5.3 Hyperparameter optimization\n",
    "\n",
    "_Points: 10_\n",
    "\n",
    "In this exercise, you'll carry out hyperparameter optimization for the hyperparameter `C` of SVC RBF classifier. In practice, you'll carry out hyperparameter optimization for all different hyperparameters of the most promising classifiers. For the purpose of this assignment, we'll only do it for the `SVC` classifier with one hyperparameter, namely `C`. \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. For each `C` value in the `param_grid` below: \n",
    "    - Create a pipeline object with two steps: preprocessor from 4.4 and `SVC` classifier with the `C` value.\n",
    "    - Carry out 5-fold cross validation with the pipeline.  \n",
    "    - Store the results in `results_dict` and display results as a pandas DataFrame. \n",
    "2. Which hyperparameter value seems to be performing the best? Store it in a variable called `best_C`. (Since this question is not autograded, please store the value directly as a number, something like `best_C = 0.001`, if `C = 0.001` is giving you the best CV score.) Is it different than the default value for the hyperparameter used by `scikit-learn`? \n",
    "\n",
    "> Note: Running this will take a while. Please be patient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': array([  0.1,   1. ,  10. , 100. ])}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\"C\": np.logspace(-1, 2, 4)}\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_5.3\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "tags": [
     "otter_assign_solution_cell"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ws/_grt5pdj4j385s9jf9wg606h0000gn/T/ipykernel_56363/4158382658.py:26: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  out_col.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores[i], std_scores[i])))\n",
      "/var/folders/ws/_grt5pdj4j385s9jf9wg606h0000gn/T/ipykernel_56363/4158382658.py:26: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  out_col.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores[i], std_scores[i])))\n",
      "/var/folders/ws/_grt5pdj4j385s9jf9wg606h0000gn/T/ipykernel_56363/4158382658.py:26: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  out_col.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores[i], std_scores[i])))\n",
      "/var/folders/ws/_grt5pdj4j385s9jf9wg606h0000gn/T/ipykernel_56363/4158382658.py:26: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  out_col.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores[i], std_scores[i])))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.1</th>\n",
       "      <th>1.0</th>\n",
       "      <th>10.0</th>\n",
       "      <th>100.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>5.989 (+/- 0.411)</td>\n",
       "      <td>4.881 (+/- 0.235)</td>\n",
       "      <td>4.569 (+/- 0.719)</td>\n",
       "      <td>5.579 (+/- 1.054)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>2.727 (+/- 0.136)</td>\n",
       "      <td>2.240 (+/- 0.192)</td>\n",
       "      <td>1.897 (+/- 0.162)</td>\n",
       "      <td>1.682 (+/- 0.171)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_score</th>\n",
       "      <td>0.800 (+/- 0.004)</td>\n",
       "      <td>0.847 (+/- 0.006)</td>\n",
       "      <td>0.850 (+/- 0.004)</td>\n",
       "      <td>0.852 (+/- 0.006)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_score</th>\n",
       "      <td>0.801 (+/- 0.002)</td>\n",
       "      <td>0.849 (+/- 0.002)</td>\n",
       "      <td>0.855 (+/- 0.002)</td>\n",
       "      <td>0.866 (+/- 0.002)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0.1                1.0                10.0   \\\n",
       "fit_time     5.989 (+/- 0.411)  4.881 (+/- 0.235)  4.569 (+/- 0.719)   \n",
       "score_time   2.727 (+/- 0.136)  2.240 (+/- 0.192)  1.897 (+/- 0.162)   \n",
       "test_score   0.800 (+/- 0.004)  0.847 (+/- 0.006)  0.850 (+/- 0.004)   \n",
       "train_score  0.801 (+/- 0.002)  0.849 (+/- 0.002)  0.855 (+/- 0.002)   \n",
       "\n",
       "                         100.0  \n",
       "fit_time     5.579 (+/- 1.054)  \n",
       "score_time   1.682 (+/- 0.171)  \n",
       "test_score   0.852 (+/- 0.006)  \n",
       "train_score  0.866 (+/- 0.002)  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict = {}\n",
    "\n",
    "for c_value in param_grid[\"C\"]:\n",
    "    \n",
    "    pipeline = make_pipeline(preprocessor, SVC(C = c_value))\n",
    "    results_dict[c_value] = mean_std_cross_val_scores(\n",
    "        pipeline, X_train, y_train, cv = 5, return_train_score = True\n",
    "    )\n",
    "\n",
    "results_dataframe = pd.DataFrame(results_dict)\n",
    "\n",
    "results_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_assign_solution_cell"
    ]
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "tags": [
     "otter_assign_solution_cell"
    ]
   },
   "outputs": [],
   "source": [
    "best_C = None\n",
    "\n",
    "best_C = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br>The default value for the hyperparameter used by scikit-learn is 1.0. On comparing it with the output above, we see that the best_c is 100, which is not the same as 1.0<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Exercise 6: Evaluating on the test set \n",
    "<hr>\n",
    "\n",
    "Now that we have a best performing model, it's time to assess our model on the set aside test set. In this exercise, you'll examine whether the results you obtained using cross-validation on the train set are consistent with the results on the test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Scoring on the unseen test set \n",
    "\n",
    "_Points: 4_\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Create a pipeline named `final_pipeline` with the preprocessor from 4.4 as the first step and the best performing SVC model from 5.4 as the second step. \n",
    "2. Train the pipeline on the entire training set `X_train` and `y_train`. \n",
    "3. Score the pipeline on `X_test` and `y_test` and store the score in a variable called `test_score`.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_6.1\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "tags": [
     "otter_assign_solution_cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8461892818754159"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pipeline = None\n",
    "test_score = None\n",
    "\n",
    "final_pipeline = make_pipeline(\n",
    "    preprocessor,\n",
    "    SVC(C = best_C)\n",
    ")\n",
    "\n",
    "final_pipeline.fit(X_train, y_train)\n",
    "\n",
    "test_score = final_pipeline.score(X_test, y_test)\n",
    "\n",
    "test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 7: Short answer questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 7.1 kNNs toy example\n",
    "\n",
    "_Points: 3_\n",
    "\n",
    "Suppose you want to get predictions using the $k$-nearest neighbour algorithm on the toy dataset below. \n",
    "\n",
    "$$ X = \\begin{bmatrix}5 & 2\\\\4 & -2\\\\  2 & 2\\\\ 10 & 10\\\\ 9 & -1\\\\ 9& 9\\end{bmatrix}, \\quad y = \\begin{bmatrix}0\\\\0\\\\1\\\\1\\\\1\\\\2\\end{bmatrix}.$$\n",
    "\n",
    "Suppose you are given a new data point $x=\\begin{bmatrix} 0\\\\0\\end{bmatrix}$.  \n",
    "\n",
    "1. What would the model predict when $k=1$?\n",
    "2. What would the model predict when $k=3$?\n",
    "3. What would the model predict when $k=3$ if we were doing regression rather than classification? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. For k = 1, we would have first to calculate the distance between the new data point and all of the other points in X. On calculating that, it can be seen the closest point is (2,2) with a Euclidean distance of sqrt(8). This point corresponds to 1 as the class label.\n",
    "2. For k = 3, we would take the closest three points, which turn out to be (2,2), (4,-2), (5,-2). These points correspond to class labels 1, 0, 0. Since the most frequently predicted class is 0, the model will predict 0.\n",
    "3. For k = 3 with regression rather than classification, we would take the average of the values which is (1 + 0 + 0)/3 = 1/3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 7.2 Preprocessing\n",
    "\n",
    "_Points: 8_\n",
    "\n",
    "1. What is the problem with calling `fit_transform` on your test data with `StandardScaler`?\n",
    "2. Why is it important to follow the Golden Rule? If you violate it, will that give you a worse classifier?\n",
    "3. What are two advantages of using sklearn Pipelines? \n",
    "4. When is it appropriate to use sklearn `ColumnTransformer`? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Calling fit_transform on our test data with StandardScaler would calculate the mean and sd, which would be specific to the test data. We want the test data to be transformed using the mean and SD of the training dataset, which wouldn't be the case here. Test data should be scaled using the training data's parameters (mean and SD) to assess model performance accurately.\n",
    "2. The Golden Rule is that we should never use test data to do model training. Test data should only be used once the model has been trained, and we need to evaluate its performance and accuracy. If we violate the Golden Rule, we will get a model that is overfitting and that does not generalize well. While the classifier would not be worse, our expectations of how the model will perform in the real world and its actual performance would differ.\n",
    "3. sklearn Pipelines streamline the whole process of preprocessing and model training into the same object. All the same transformations applied in training, testing, or evaluating are simplified and encapsulated. \n",
    "4. It is appropriate to use sklearn ColumnTransformer when we want to perform different transformations to different columns in the dataset. Considering the above example with different types of variables requiring scaling and binary transformations, ColumnTransformer is really helpful here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission instructions \n",
    "\n",
    "**PLEASE READ:** When you are ready to submit your assignment do the following:\n",
    "\n",
    "1. Run all cells in your notebook to make sure there are no errors by doing `Kernel -> Restart Kernel and Clear All Outputs` and then `Run -> Run All Cells`. \n",
    "2. Notebooks with cell execution numbers out of order or not starting from “1” will have marks deducted. Notebooks without the output displayed may not be graded at all (because we need to see the output in order to grade your work).\n",
    "3. Upload the assignment using [PrairieLearn](https://ca.prairielearn.com/pl/course_instance/6697)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations on finishing the homework! This was a tricky one but I hope you are feeling good after working on it. You are now ready to build a simple supervised machine learning pipeline on real-world datasets! Well done :clap:! \n",
    "\n",
    "![](img/eva-well-done.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python [conda env:cpsc330]",
   "language": "python",
   "name": "conda-env-cpsc330-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1.1": {
     "name": "q1.1",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert not train_df is None and not test_df is None, \"Please use the provided variables.\"\n>>> assert train_df.shape == (13024, 15), \"The dimensions of the training set are incorrect\"\n>>> assert test_df.shape == (19537, 15), \"The dimensions of the test set are incorrect\"\n>>> assert train_df.loc[12846][['age', 'education', 'occupation', 'capital.loss']].tolist() == [49, 'Some-college', 'Craft-repair', 0], \"Are you using the provided random state?\"\n>>> assert not 20713 in train_df.index, 'Are you using the provided random state?' \n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.1": {
     "name": "q2.1",
     "points": [
      1,
      1,
      1,
      1,
      1
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # Task 1\n>>> assert isinstance(census_summary, pd.DataFrame), \"census_summary dataftame is not created\"\n>>> assert census_summary.shape == (11, 15), \"census_summary shape is incorrect. Probably you are not including all columns\"\n>>> assert census_summary.loc['min']['age'] == 17.0, \"census_summary dataframe is incorrect\"\n>>> assert census_summary.loc['top']['occupation'] == \"Prof-specialty\", \"census_summary dataframe is incorrect\"\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> # Task 2\n>>> assert (sha1(str(max_hours_per_week).encode('utf8')).hexdigest() == \"3359de52c8ae993fe0f8fe9c5168a0065bd3c7a4\"), \"max_hours_per_week are incorrect\"\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> # Task 3\n>>> assert (sha1(str(most_freq_occupation).encode('utf8')).hexdigest() == \"97165f50eddb0d28a382b0366274e2fe38505644\"), \"most_freq_occupation is incorrect\"\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> # Task 4\n>>> assert (sha1(str(missing_vals_cols).encode('utf8')).hexdigest() == \"6bc5e13d4d66b306e52701ee9a1e5e21bf19aeb0\"), \"Please use the exact column/feature name. Also, make sure the lists are sorted.\"\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> # Task 5\n>>> assert (sha1(str(numeric_cols).encode('utf8')).hexdigest() == \"615afaf5011128d641ab8a73289d57bd01a3ec37\"), \"Please use the exact column/feature name. Also, make sure the lists are sorted.\"\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.4": {
     "name": "q2.4",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert (sha1(str(numeric_features).encode('utf8')).hexdigest() == \"71401cf60034fd69eee7398866359f612adf3e15\"), \"numeric_features list is not correct\"\n>>> assert (sha1(str(categorical_features).encode('utf8')).hexdigest() == \"af1a4022c0362405678be5c3a6735578a8c0069f\"), \"categorical_features list is not correct\"\n>>> assert (sha1(str(ordinal_features).encode('utf8')).hexdigest() == \"95b86602c44211f3ad662bb58b8e53d024106d05\"), \"ordinal_features list is not correct\"\n>>> assert (sha1(str(binary_features).encode('utf8')).hexdigest() == \"d4b7aa4c56ac2f98e6ac9cec7768484b415b7337\"), \"binary_features list is not correct\"\n>>> assert (sha1(str(drop_features).encode('utf8')).hexdigest() == \"62aab57d42c54be3dfd3c55020e5a167ca1a84c3\"), \"drop_features list is not correct\"\n>>> assert (sha1(str(target).encode('utf8')).hexdigest() == \"0f613350b66e64d92ef21bc4dcdbf8996cb4edf0\"), \"target variable is not set correctly\"\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3.1": {
     "name": "q3.1",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert not X_train is None, \"Your answer does not exist. Have you passed in the correct variable?\"\n>>> assert not y_train is None, \"Your answer does not exist. Have you passed in the correct variable?\"\n>>> assert not X_test is None, \"Your answer does not exist. Have you passed in the correct variable?\"\n>>> assert not y_test is None, \"Your answer does not exist. Have you passed in the correct variable?\"\n>>> assert X_train.shape == (13024, 14), \"The dimensions of X_train are incorrect\"\n>>> assert y_train.shape == (13024, ), \"The dimensions of y_train are incorrect. Are you splitting correctly\"\n>>> assert X_test.shape == (19537,14), \"The dimensions of X_test are incorrect. Are you splitting correctly? Are you using single brackets?\"\n>>> assert y_test.shape == (19537,), \"The dimensions of y_test are incorrect. Are you splitting correctly? Are you using single brackets?\"\n>>> assert 'income' not in list(X_train.columns), \"Make sure the target variable is not part of your X dataset.\"\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3.2": {
     "name": "q3.2",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert not dummy_df is None, \"Have you used the correct variable to store the results?\"\n>>> assert sorted(list(dummy_df.columns)) == ['fit_time','score_time','test_score','train_score'], \"Your solution contains incorrect columns.\"\n>>> assert dummy_df.shape == (5,4), \"Are you carrying out 5-fold cross-validation and are you passing return_train_score=True?\"\n>>> assert sha1(str(round(dummy_df['test_score'].mean(),3)).encode('utf8')).hexdigest() == \"e04884a1f90ee71d58aa5550207e305cd0e18392\", \"The test scores seem wrong. Are you calling cross_validate correctly?\"\n>>> assert sha1(str(round(dummy_df['train_score'].mean(),3)).encode('utf8')).hexdigest() == \"e04884a1f90ee71d58aa5550207e305cd0e18392\", \"The train scores seem wrong. Are you calling cross_validate correctly?\"\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4.1": {
     "name": "q4.1",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert not ordinal_transformer is None, \"Are you using the correct variable name?\"\n>>> assert type(ordinal_transformer.get_params()['categories'][0]) is list, \"Are you passing education levels as a list of lists?\"\n>>> assert ordinal_transformer.get_params()['dtype'] == int, \"Please set the dtype to int\"\n>>> assert (sha1(str(ordinal_transformer.get_params()['categories'][0]).encode('utf8')).hexdigest() == \"893a03d114b2af09b53247866c6eea54ebfd090f\") or (sha1(str(ordinal_transformer.get_params()['categories'][0]).encode('utf8')).hexdigest() == \"81059b8bebc9ddb03d61bf07cfd9b9b6b0da288e\"), \"Make sure you are passing categories sorted on levels of education. (Ascending or descending shouldn't matter.)\"\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4.2": {
     "name": "q4.2",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert not binary_transformer is None, \"Are you using the correct variable name?\"\n>>> assert binary_transformer.get_params()['drop'] == 'if_binary', \"Are you passing `drop=if_binary`?\"\n>>> assert binary_transformer.get_params()['dtype'] == int, \"Please set the dtype to int\"\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4.3": {
     "name": "q4.3",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert not categorical_transformer is None, \"Are you using the correct variable name?\"\n>>> assert type(categorical_transformer) is Pipeline, \"Are you creating a scikit-learn Pipeline?\"\n>>> assert len(categorical_transformer.get_params()['steps']) == 2, \"Are you creating a pipeline with two steps?\"\n>>> assert categorical_transformer.get_params()['simpleimputer__strategy'] == 'constant', \"Are you passing strategy=constant in the SimpleImputer?\"\n>>> assert categorical_transformer.get_params()['simpleimputer__fill_value'] == 'missing', \"Are you passing fill_value='missing' in the SimpleImputer?\"\n>>> assert categorical_transformer.get_params()['onehotencoder__handle_unknown'] == 'ignore', \"Are you passing handle_unknown = 'ignore' argument to your OHE?\"\n>>> assert categorical_transformer.get_params()['onehotencoder__sparse'] == False, \"Are you creating a sparse matrix for OHE?\"\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4.4": {
     "name": "q4.4",
     "points": [
      5,
      1,
      1
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # task 1\n>>> assert not preprocessor is None, \"Are you using the correct variable name?\"\n>>> assert len(preprocessor.get_params()['transformers']) in range(4,6,1), \"Have you included all the transformers?\"\n>>> assert 'onehotencoder' in preprocessor.get_params().keys(), 'Either the categorical_transformer or binary_transformer is not included.'\n>>> assert 'standardscaler' in preprocessor.get_params().keys(), 'numeric_transformer is not included.'\n>>> assert 'ordinalencoder' in preprocessor.get_params().keys(), 'ordinal_transformer is not included.'\n>>> assert 'drop' in preprocessor.get_params().keys(), 'drop features step is not included.'\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> # task 2\n>>> assert not transformed_df is None, \"Are you using the correct variable name?\"\n>>> assert sha1(str(transformed_df.shape).encode('utf8')).hexdigest() == 'a0521f0cdbcd77cd213e7d1a3cfc13c1c7c92a6e', \"The shape of the transformed data is incorrect.\"\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert sha1(str(n_new_cols).encode('utf8')).hexdigest() == 'b7103ca278a75cad8f7d065acda0c2e80da0b7dc', \"The number of new columns (n_new_cols) is incorrect.\"\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6.1": {
     "name": "q6.1",
     "points": [
      2,
      2
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # task 1\n>>> assert not final_pipeline is None, \"Are you using the correct variable name?\"\n>>> assert not test_score is None, \"Are you using the correct variable name?\"\n>>> assert len(final_pipeline.named_steps) == 2, \"The final pipeline needs to have two steps: one for the preprocessor and one for SVC.\"\n>>> assert final_pipeline.n_features_in_ == 14, \"Make sure to pass the original X_train to fit\"\n>>> assert final_pipeline.named_steps['svc'].get_params()['C'] == best_C, \"Are you using the best C value from the previous exercise?\"\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> # task 2\n>>> assert not test_score is None, \"Are you using the correct variable name?\"\n>>> assert sha1(str(round(test_score,3)).encode('utf8')).hexdigest() == '1284d7d1d642ef8e51475cce5c1972ca6b8bd2b6', \"The test score seems off\"\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
